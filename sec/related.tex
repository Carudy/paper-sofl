Homomorphic encryption based solutions are intuitively effective to solve aggregation problems, and there are many researches tried to reduce the overhead caused by HE\cite{abs-1711-10677,BatchCrypt}. However, they still cost much time on computation compared to MPC based and DP based methods. DP based solutions have better performance than HE based solutions, and many works proved DP does not reduce the accuracy of machine learning models in some particular situations\cite{Bayesian,DPAnalysis,ZhuDP,geyer2017differentially}. Whereas these methods did not prove DP does not impact the accuracy in other more complicated and large-scale models. MPC based methods have the least computation cost but requires more communications. A typical MPC federated learning model is implemented by Google\cite{Practical}. It requires pairwise key exchangement among all clients, which results in enormous overhead on communication. Other researches present hybrid methods\cite{Hybrid,HybridAlpha}. These hybrid methods combine MPC with either HE or DP and make tradeoff on computation and communication.

Federated learning is more and more practical nowadays. FATE\cite{fate} is an open-source federated learning project proposed by Webankâ€™s AI Department. It adopts both MPC and HE to implement secure aggregation, while it is still absorbing state-of-the-art methods for privacy-perserving. Pysyft\cite{pysyft} is another open-source federated learning framework presented by OpenMined. It is based on Pytorch and offers HE, DP and MPC as alternative methods to realize privacy-preserving. However, the cost of time of Pysyft is dozens of times than pure Pytorch, which indicates that privacy-preserving methods of current federated learning platforms need to be improved.


