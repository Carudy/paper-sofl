Smart phones and other devices in daily life are equipped with more and more powerful computing and storage abilities, which enables individual devices accumulate more and more valuable information. It facilitated a lot of rising technologies such as edge computing. Meanwhile, the accumulated data in users' devices can be used to train models for various practical purposes due to the flourish of machine learning. In traditional machine learning frameworks, data needs to be gathered in a center server in order to execute the learning process. However, most data collected by mobile devices is sensitive. Users usually refuse to send their private data to others, such as a learning center. 

Federated Learning\cite{mcmahan2016communicationefficient} is designed to address this problem. In each round, FL parties receive a global model from the server, and they train their the model based on their own data respectively. Afterwards, the partes send the parameters of their own models to the server while the server run a particular algorithm to compute the global model based on these parameters. In such frameworks, users don't need to send their data to the learning server, which can protect the privacy to some extent.

However, many researches have shown that attackers are able to infer users' data through the leaked information about the model's parameters\cite{Beyond, Leakage}. Therefore, sending parameters to the server directly is no longer secure. Secure aggregation protocols allow a group of parties who have private information to compute a function which takes these private values as parameters. Researchers paid their attention to secure aggregation for a better solution\cite{shi2011privacy,RobustAgg,Bonawitz19,Nike,PrivFL}. There are 3 primary methods to achieve privacy-preserving in secure aggregation: Differential Privacy (DP), homomorphic encryption (HE), and secure multi-party computation. DP enabled FL\cite{Bayesian,DPAnalysis,ZhuDP,geyer2017differentially,Hybrid} focuses on provides privacy-preserving while keep the accuracy of machine learning model. Since these studies did not conduct experiments with complicated machine learning models while some researches have pointed out that DP based FL will impact the accuracy of the learned model\cite{Two-Phase}, it is still a challenge to employ DP in FL. Homomorphic encryption algorithms are intuitionistic and simple to protect privacy, however they suffer from low efficiency which is hardly accecptable in FL. Blockchain-based methods\cite{DeepChain,Lu2020,On-Device} are also very promising, and the generally used consensus algorithms in them can be inspiring. Yet blockchain-based methods are still implement-unfriendly. Therefore, adopting MPC to protect users' privacy is more practical. There are many researches protecting the parameters based on MPC\cite{Practical,Two-Phase,Weighted,Hybrid}. 

Secure multi-party computation can be implemented by garbled circuits or secret sharing methods\cite{Shamir}. Garbled circuits have many limits and low effiency. Therefore, we choose to use secret sharing methods. Normally, secret sharing needs parties to exchange information among themselves. However, in federated learning frameworks, the parties are usually strange to each other, which means one party does not have the addresses of others. A party cannot communicate with other parties directly and they can only exchange information securely with the help of the server. In this case, Bonawitz etc.\cite{Practical} proposed a method about constructing secure channels among FL parties. Constructing secure channels between every pair of parties cost plenty of time, which leads to a new problem. In addition, the robustness of FL frameworks is also significant because it usually costs a lot to recover from situations that several nodes are crashed. In summary, employing traditional MPC methods in a system with large number of users is faced with a problem about efficiency and instability.

In this paper, we propose Self-organizing Federated Learning (SOFL), a novel FL framework which utilizes MPC to protects users' privacy and takes advantages of consensus algorithms to achieve high efficiency and robustness. Our model first elects some leaders, who will construct secure commnunication with other parties. Afterwards, a party only needs to exchange information with the leaders. The leaders will send the received information to the server, who helps forwarding the information to the corresponding destinations. Appointing leaders reduces the need of communications greatly and running a consensus algorithm can handle unexpected situations where a leader node or a common client is crashed. We adopted MPC protocols similar with Zhu etc\cite{Weighted}. Our model also has strong robustness based on the consensus algorithm. 

\textbf{Roadmap:} In Section~\ref{sec:back} we introduce the background of knowledge and some definitions. Next we introduce platforms of federated learning in Section~\ref{sef:related}. Section~\ref{sec:sofl} detailedly illustrates our proposed framework while describes the attack model. Evaluations for efficiency and security are stated in Section~\ref{sec:eval}, followed with experiments and results in Section~\ref{sec:exp}. Finally, we give the conclusion and future expectations in Section~\ref{sec:conc}.