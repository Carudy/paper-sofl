Smartphones and other devices in daily life are equipped with more and more powerful computing and storage abilities, which enables individual devices to accumulate more and more valuable information. It facilitated a lot of rising technologies such as edge computing. Meanwhile, the accumulated data in users' devices can be used to train models for various practical purposes due to the flourishing of machine learning. In traditional machine learning frameworks, data needs to be gathered in a central server in order to execute the learning process. However, most data collected by mobile devices is sensitive. Users usually refuse to send their private data to others, such as a learning center. 

Federated Learning\cite{mcmahan2016communicationefficient} is designed to address this problem. In each round, FL parties receive a global model from the server, and they train their model based on their own data respectively. Afterwards, the parties send the parameters of their models to the server while the server runs a particular algorithm to compute the global model based on these parameters. In such frameworks, users don't need to send their data to the learning server, which can protect privacy to some extent.

However, many researchers have shown that attackers are able to infer users' data through the leaked information about the model's parameters\cite{Beyond, Leakage}. Therefore, sending parameters to the server directly is no longer secure. Secure aggregation protocols allow a group of parties who have private information to compute a function that takes these private values as parameters. Researchers paid their attention to secure aggregation for a better solution\cite{shi2011privacy,RobustAgg,Bonawitz19,Nike,PrivFL}. There are 3 primary methods to achieve privacy-preserving in secure aggregation: Differential Privacy (DP), homomorphic encryption (HE), and secure multi-party computation. DP enabled FL focuses on provides privacy-preserving while keeping the accuracy of the machine learning model. Since these studies did not conduct experiments with complicated machine learning models while some researches have pointed out that DP based FL will impact the accuracy of the learned model\cite{Two-Phase}, it is still a challenge to employ DP in FL. Homomorphic encryption algorithms are intuitionistic and simple to protect privacy, however, they suffer from low efficiency which is hardly acceptable in FL\cite{HESurvey}. Blockchain-based methods\cite{DeepChain,Lu2020,On-Device} are also very promising, and the generally used consensus algorithms in them can be inspiring. Yet blockchain-based methods are still implement-unfriendly. Therefore, adopting MPC to protect users' privacy is more practical. Many types of research are protecting the parameters based on MPC\cite{Practical,Two-Phase,Weighted,Hybrid}. 

Secure multi-party computation can be implemented by garbled circuits or secret sharing methods\cite{Shamir}. Garbled circuits have many limits and low efficiency. Therefore, we choose to use secret sharing methods. Normally, secret sharing needs parties to exchange information among themselves. However, in federated learning frameworks, the parties are usually strange to each other, which means one party does not have the addresses of others. A party cannot communicate with other parties directly and they can only exchange information securely with the help of the server. In this case, Bonawitz etc.\cite{Practical} proposed a method about constructing secure channels among FL parties. Constructing secure channels between every pair of parties cost plenty of time, which leads to a new problem. In addition, the robustness of FL frameworks is also significant because it usually costs a lot to recover from situations that several nodes are crashed. In summary, employing traditional MPC methods in a system with a large number of users is faced with a problem with efficiency and instability.

\textbf{Our contribution: }In this paper, we propose Self-organizing Federated Learning (SOFL), a novel FL framework that utilizes MPC to protects users' privacy and takes advantage of consensus algorithms to achieve high efficiency and robustness. Our model first elects some leaders, who will construct secure communication with other parties. Afterwards, a party only needs to exchange information with the leaders. The leaders will send the received information to the server, who helps to forward the information to the corresponding destinations. Appointing leaders reduces the need for communications greatly and running a consensus algorithm can handle unexpected situations where a leader node or a common client is crashed. We adopted a simple additive secret sharing protocol to realize MPC. Our model also has strong robustness based on the consensus algorithm due to the consensus algorithm. 

\textbf{Roadmap:} In Section~\ref{sec:back} we introduce the background of knowledge and some definitions. Next, we introduce related work and some platforms of federated learning in Section~\ref{sec:related}. Section~\ref{sec:sofl} detailedly illustrates our proposed framework while describes the attack model. Evaluations for efficiency and security are stated in Section~\ref{sec:eval}, followed with experiments and results in Section~\ref{sec:exp}. Finally, we give the conclusion and future expectations in Section~\ref{sec:conc}.