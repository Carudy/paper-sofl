\subsection{Communications}
As illustrated in Section III, our framework only adopts lightweight algorithms to enhance security. Therefore, the execution overhead can be ignored compared to the communication overhead. Notice that any communication in our framework goes through the server. E.g., if $P_i$ wants to send encrypted message $c$ to $L_j$, $c$ will be sent to server $S$ first. Afterwards $S$ will forward $c$ to $L_j$. In general, our P2P communications are emulated with client/server communications. This method accelerates communication greatly because it costs much for two strangers to exchange messages directly. E.g., if two users want to communicate directly, both of them need to store the addresses, confirm the ``accept'' signal after each message-exchange, \emph{et al}. However, with a powerful server helping to forward, these things are no longer concerns for users.

In each round, there are $n$ common users and $N_l$ leaders. To analyze the communication overhead clearly and without loss of generality, we can suppose there is no common user that is also a leader at the same time. Common users, leaders together with the server $S$ are all users requiring communication. Generally, $N_l$ is a very small number such as 3, therefore we can treat it as a constant number. Our framework can be categorized into \textbf{set-up} and \textbf{secure-learning} two phases. We analyze these two phases respectively:

\begin{itemize}
    \item \textbf{Set-up:} First, all $n$ users will send ``self-recommendation'' messages to decide who the leaders are, then $n - N_l$ common users need to construct secure channels with all $N_l$ leaders. Afterwards, the server will send $L$ to all $n$ users. Suppose it needs $D$ communications in each DH protocol, then the amount of communications of the set-up phase is $n + n + D * (n - N_l) * N_l$. The time complexity is $O(n)$ based on the fact that $D$ and $N_l$ are small constant numbers.
    
    In the reorganization process, $n - N_l$ common users will send ``self-recommendation'' messages to decide a new leader. The new leader then conducts DH protocols with all $n - N_l - 1$ users, which is $D * (n - N_l - 1)$ communications. Therefore, a reorganization process also costs $O(n)$ communications.
    
    \item \textbf{Secure-learning:} In each epoch, $S$ sends the current $W_\textrm{global}$ to $n$ users, which cost $n$ communications. Then each common user sends $W_{ij}$ to $N_l$ leaders respectively, which cost $n * N_l$ communications. Afterwards, each leader sends $B_j$ to the server and waits for the intersecion, which cost $2 * N_l$ communications. Finally leaders send $Aj$ to $S$, which cost $N_l$ communications. Thus the total cost of one epoch is $n + n * N_l + 3 * N_l$, which is $O(n)$.
\end{itemize}

In the time complexity aspect, our framework does not result in higher overhead expect for an $O(n)$ preprocessing compared to the original FedAvg algorithm. In the vertical aspect, our framework does not require more message-exchanges for any party-leader pair. 

\subsection{Security Evaluation}
The evaluation is based on the fact that our adversaries are all honest-but-curious. Since our framework is based on MPC researches, the proof of security against message-leakage can be referred~\cite{Shamir,Du2001SecureMC,Three-Party}. And the security of using MPC in FL has been proved by Zhu \emph{et al.}~\cite{Weighted} The riskiest threat is the collusion attack. Colluding with a common party has no contribution to an attack because it lets out nothing but the information about this common party, which belongs to the attacker side. Therefore, we only discuss collusions among the server and leaders. 

Apparently, the attacker must collude with all leaders in order to reconstruct one party's parameter. Since the leaders are assigned randomly based on the consensus algorithm, it is hardly possible for all attackers to be insincere at the same time. However, it is necessary to discuss the situation where the server cheats to select leaders as its wish by other means such as slowing down the sincere users' network. In such situations, the leaders are always selected by the unreliable server. To address this problem, we introduced ``leader-tenure'' in Section III, which forces the system to change leaders regularly. Since it needs all leaders' betrayal to attack successfully, the system only needs to change one leader regularly. Changing one leader is equivalent to a reorganization process, whose time cost is $O(n)$. Therefore, our framework has high security against collusive honest-but-curious attackers.
